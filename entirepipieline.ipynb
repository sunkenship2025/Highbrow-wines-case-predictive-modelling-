{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7831289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    OneHotEncoder,\n",
    "    FunctionTransformer\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "#import train_test_split from sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69205a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fd966bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load our data\n",
    "data = pd.read_csv('data_2016.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "243a522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets train test split\n",
    "X = data.drop(columns=['bought_highbrow_wines'])\n",
    "y = data['bought_highbrow_wines']\n",
    "#lets drop x values whose y is nan\n",
    "X = X.loc[y.dropna().index]\n",
    "y = y.dropna()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e7e43f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cat_sum'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mpandas/_libs/index.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/index.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'cat_sum'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#cogo overlap test\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m (\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcat_sum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcogo_rev\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m-\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_spend\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:4113\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4113\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4115\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3817\u001b[0m     ):\n\u001b[0;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'cat_sum'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ded343f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Consolidated feature engineering + feature selection.\n",
    "    creates:\n",
    "    - Intent signals (wine/premium purchase history)\n",
    "    - Ability signals (spend capacity)\n",
    "    - Willingness signals (price sensitivity, discount behavior)\n",
    "    - Channel readiness (online purchase patterns)\n",
    "    - Stable context (household, loyalty)\n",
    "    - Flags for anomalies (SOW_!, negative values)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    \n",
    "    # identify all category columns for aggregations\n",
    "\n",
    "    cat_cols = [c for c in df.columns if c.startswith(\"cat_\")]\n",
    "    \n",
    "    # Coerce all cat_* to numeric\n",
    "    for c in cat_cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0)\n",
    "    \n",
    "\n",
    "    #  CREATE FLAGS \n",
    "    # SOW_! flag: capture outlier indicator before normalizing\n",
    "    if \"SOW_type_colr\" in df.columns:\n",
    "        df[\"SOW_!\"] = (df[\"SOW_type_colr\"] == \"!\").astype(int)\n",
    "    \n",
    "    # Negative value flags for cat_* columns (possible returns/refunds)\n",
    "    for c in cat_cols:\n",
    "        if (df[c] < 0).any():\n",
    "            df[f\"{c}_neg_flag\"] = (df[c] < 0).astype(int)\n",
    "    \n",
    "\n",
    "    #  AGGREGATE FEATURES\n",
    "\n",
    "    # Total spend (sum of all category purchases)\n",
    "    df[\"total_spend\"] = df[cat_cols].sum(axis=1)\n",
    "    \n",
    "    # Online channel features\n",
    "    df[\"n_cogo\"] = pd.to_numeric(df.get(\"n_cogo\", 0), errors=\"coerce\").fillna(0)\n",
    "    df[\"cogo_rev\"] = pd.to_numeric(df.get(\"cogo_rev\", 0), errors=\"coerce\").fillna(0)\n",
    "    \n",
    "    df[\"online_channel_ratio\"] = np.where(\n",
    "        df[\"total_spend\"] > 0,\n",
    "        df[\"cogo_rev\"] / df[\"total_spend\"],\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    # Discount behavior\n",
    "    df[\"total_discount\"] = pd.to_numeric(df.get(\"total_discount\", 0), errors=\"coerce\").fillna(0)\n",
    "    \n",
    "    df[\"discount_ratio\"] = np.where(\n",
    "        df[\"total_spend\"] > 0,\n",
    "        df[\"total_discount\"] / df[\"total_spend\"],\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    \n",
    "    #  WINE AFFINITY FEATURES\n",
    "    \n",
    "    # Wine-adjacent premium foods that signal taste alignment\n",
    "    wine_affinity_cols = [\n",
    "        \"cat_Wijn_Stillewijnen_RAYON\",     # Still wines (anchor)\n",
    "        \"cat_Tapas\",                      # Wine-paired appetizers\n",
    "        \"cat_KaasSeizoenskazen\",           # Seasonal / specialty cheeses\n",
    "        \"cat_VerseKaasFruitkazen\",         # Fresh / fruit cheeses\n",
    "        \"cat_VisGerookt\",                  # Smoked fish\n",
    "        \"cat_VisVerseSchelpdieren\",        # Fresh fish & shellfish\n",
    "    ]\n",
    "    wine_affinity_cols = [c for c in wine_affinity_cols if c in df.columns]\n",
    "    \n",
    "    df[\"wine_affinity_spend\"] = df[wine_affinity_cols].sum(axis=1) if wine_affinity_cols else 0\n",
    "    \n",
    "    df[\"wine_affinity_ratio\"] = np.where(\n",
    "        df[\"total_spend\"] > 0,\n",
    "        df[\"wine_affinity_spend\"] / df[\"total_spend\"],\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    \n",
    "    #  PREMIUM VS NECESSITY RATIO\n",
    "    # Premium lifestyle categories (discretionary, taste-driven)\n",
    "    premium_cols = [\n",
    "        \"cat_Wijn_Stillewijnen_RAYON\",   # Premium anchor\n",
    "        \"cat_Tapas\",                    # Gourmet food\n",
    "        \"cat_KaasSeizoenskazen\",         # Specialty cheese\n",
    "        \"cat_VisGerookt\",               # Premium fish\n",
    "        \"cat_Bier_Genietbieren\",         # Craft / premium beers\n",
    "        \"cat_Bloemen\",                  # Gifting / discretionary\n",
    "        \"cat_ParfumerieEHBO\",            # Personal care / premium\n",
    "        \"cat_Textiel_Bedlinnen\",         # Lifestyle / home comfort\n",
    "    ]\n",
    "    premium_cols = [c for c in premium_cols if c in df.columns]\n",
    "    \n",
    "# Necessity categories (survival shopping, family logistics)\n",
    "    necessity_cols = [\n",
    "        \"cat_Babyluiers\",                # Baby diapers\n",
    "        \"cat_Incontinentie_luiers\",      # Adult diapers\n",
    "        \"cat_MelkKarnemelk\",             # Basic dairy\n",
    "        \"cat_BroodKorthoudbaar\",         # Bread staples\n",
    "        \"cat_Bot_Mar_Boter\",             # Butter (basic)\n",
    "    ]\n",
    "    necessity_cols = [c for c in necessity_cols if c in df.columns]\n",
    "    \n",
    "    premium_spend = df[premium_cols].sum(axis=1) if premium_cols else 0\n",
    "    necessity_spend = df[necessity_cols].sum(axis=1) if necessity_cols else 0\n",
    "    \n",
    "# Premium ratio: lifestyle orientation vs survival shopping\n",
    "    df[\"premium_ratio\"] = np.where(\n",
    "        (premium_spend + necessity_spend) > 0,\n",
    "        premium_spend / (premium_spend + necessity_spend),\n",
    "        0.5  # Neutral if no signal\n",
    "    )\n",
    "    \n",
    "    \n",
    "    #  CLEAN OTHER NUMERIC FEATURES\n",
    "    \n",
    "    df[\"rev_ticket\"] = pd.to_numeric(df.get(\"rev_ticket\", 0), errors=\"coerce\").fillna(0)\n",
    "    df[\"prod_ticket\"] = pd.to_numeric(df.get(\"prod_ticket\", 0), errors=\"coerce\").fillna(0)\n",
    "    df[\"price_sens_colr\"] = pd.to_numeric(df.get(\"price_sens_colr\", 0), errors=\"coerce\").fillna(0)\n",
    "    df[\"SOW_colr\"] = pd.to_numeric(df.get(\"SOW_colr\", 0), errors=\"coerce\").fillna(0)\n",
    "    \n",
    "    # Keep wine anchor feature directly\n",
    "    if \"cat_Wijn_Stillewijnen_RAYON\" in df.columns:\n",
    "        df[\"cat_Wijn_Stillewijnen_RAYON\"] = pd.to_numeric(\n",
    "            df[\"cat_Wijn_Stillewijnen_RAYON\"], errors=\"coerce\"\n",
    "        ).fillna(0)\n",
    "    \n",
    "    \n",
    "    #  HANDLE CATEGORICAL FEATURES\n",
    "    \n",
    "    # HOUSEHOLDTYPOLOGY: normalize \"!\" to \"unknown\"\n",
    "    if \"HOUSEHOLDTYPOLOGY\" in df.columns:\n",
    "        df[\"HOUSEHOLDTYPOLOGY\"] = (\n",
    "            df[\"HOUSEHOLDTYPOLOGY\"]\n",
    "            .fillna(\"unknown\")\n",
    "            .replace(\"!\", \"unknown\")\n",
    "            .astype(str)\n",
    "        )\n",
    "    \n",
    "    if \"SOW_type_colr\" in df.columns:\n",
    "        df[\"SOW_type_colr\"] = (\n",
    "            df[\"SOW_type_colr\"]\n",
    "            .fillna(\"unknown\")\n",
    "            .replace(\"!\", \"unknown\")\n",
    "            .astype(str)\n",
    "        )\n",
    "    \n",
    "    \n",
    "    # SELECT FINAL FEATURE SET\n",
    "    \n",
    "    final_numeric = [\n",
    "        \"total_spend\",\n",
    "        \"rev_ticket\",\n",
    "        \"prod_ticket\",\n",
    "        \"n_cogo\",\n",
    "        \"cogo_rev\",\n",
    "        \"online_channel_ratio\",\n",
    "        \"price_sens_colr\",\n",
    "        \"discount_ratio\",\n",
    "        \"cat_Wijn_Stillewijnen_RAYON\",\n",
    "        \"wine_affinity_spend\",\n",
    "        \"wine_affinity_ratio\",\n",
    "        \"premium_ratio\",\n",
    "        \"SOW_colr\",\n",
    "        \"SOW_!\",  # Added: outlier flag\n",
    "    ]\n",
    "    \n",
    "    # Add any neg_flag columns that were created\n",
    "    neg_flag_cols = [c for c in df.columns if c.endswith(\"_neg_flag\")]\n",
    "    final_numeric.extend(neg_flag_cols)\n",
    "    \n",
    "    final_categorical = [\n",
    "        \"HOUSEHOLDTYPOLOGY\",\n",
    "        \"SOW_type_colr\",\n",
    "    ]\n",
    "    \n",
    "    # Only keep columns that exist\n",
    "    final_numeric = [c for c in final_numeric if c in df.columns]\n",
    "    final_categorical = [c for c in final_categorical if c in df.columns]\n",
    "    \n",
    "    return df[final_numeric + final_categorical], final_numeric, final_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ae08a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_engineering() is now integrated into final_features()\n",
    "# This cell kept for reference but function removed to avoid confusion\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11415cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ClipLog(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Log1p transform with negative clipping. Supports get_feature_names_out.\"\"\"\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # Store feature names if available\n",
    "        if hasattr(X, 'columns'):\n",
    "            self._feature_names = list(X.columns)\n",
    "        elif hasattr(X, 'shape'):\n",
    "            self._feature_names = [f\"x{i}\" for i in range(X.shape[1])]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        arr = np.array(X, dtype=float, copy=True)\n",
    "        arr[arr < 0] = 0\n",
    "        return np.log1p(arr)\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        \"\"\"Required for sklearn pipeline feature name propagation because we have custom transformer so it is not letting sklearn infer names.\"\"\"\n",
    "        if input_features is not None:\n",
    "            return np.array(input_features)\n",
    "        return np.array(self._feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b402dc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #making categories \n",
    "# # Spend / turnover-like features\n",
    "# spend_cols = [col for col in X_train.columns if col.startswith(\"cat_\")] + [\n",
    "#     \"cogo_rev\",\n",
    "#     \"total_discount\",\n",
    "#     \"rev_ticket\"\n",
    "# ]\n",
    "\n",
    "# # Count-like features (can also be scaled)\n",
    "# count_cols = [\n",
    "#     \"prod_ticket\",\n",
    "#     \"n_cogo\"\n",
    "# ]\n",
    "\n",
    "# # Other numeric features\n",
    "# other_numeric_cols = [\n",
    "#     \"price_sens_colr\",\n",
    "#     \"SOW_colr\"\n",
    "# ]\n",
    "\n",
    "# numeric_cols = spend_cols + count_cols + other_numeric_cols\n",
    "\n",
    "# categorical_cols = [\n",
    "#     \"HOUSEHOLDTYPOLOGY\",\n",
    "#     \"SOW_type_colr\"\n",
    "# ]\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#we are doing diff transforms based on feature groups binary, log_numeric, categorical\n",
    "# infer_feature_groups() removed - using explicit feature groups in finalpipeline()\n",
    "# Explicit groups are preferred for interpretability and control\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a62f9fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalpipeline(numeric_cols: list, categorical_cols: list):\n",
    "    \"\"\"\n",
    "        \n",
    "        \n",
    "    Key design choices:\n",
    "    - ElasticNet regularization (handles correlated features properly) and chosen for interpretability over black-box models (e.g. tree ensembles despite their slightly higher raw performance)\n",
    "    - Log-transform for skewed spend features\n",
    "    - StandardScaler for all numeric (critical for regularization)\n",
    "    - OneHotEncoder for categoricals\n",
    "    \"\"\"\n",
    "    # Separate log-transform candidates (spend/revenue features) from others\n",
    "    log_transform_cols = [\n",
    "        \"total_spend\",\n",
    "        \"cogo_rev\",\n",
    "        \"cat_Wijn_Stillewijnen_RAYON\",\n",
    "        \"wine_affinity_spend\",\n",
    "        \"rev_ticket\",\n",
    "    ]\n",
    "    log_transform_cols = [c for c in log_transform_cols if c in numeric_cols]\n",
    "    \n",
    "    # Non-log numeric (ratios, counts, scores, flags - already bounded or normalized)\n",
    "    standard_numeric_cols = [c for c in numeric_cols if c not in log_transform_cols]\n",
    "    \n",
    "    # Log-transform pipeline (for skewed spend features)\n",
    "    log_numeric_pipeline = Pipeline([\n",
    "        (\"impute\", SimpleImputer(strategy=\"constant\", fill_value=0)),\n",
    "        (\"clip_log\", ClipLog()),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    # Standard numeric pipeline (for ratios, scores, counts, flags)\n",
    "    standard_numeric_pipeline = Pipeline([\n",
    "        (\"impute\", SimpleImputer(strategy=\"constant\", fill_value=0)),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    # Categorical pipeline (sklearn version compatibility)\n",
    "    try:\n",
    "        ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    except TypeError:\n",
    "        ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "    \n",
    "    categorical_pipeline = Pipeline([\n",
    "        (\"impute\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "        (\"ohe\", ohe)\n",
    "    ])\n",
    "    \n",
    "    # Build transformers list dynamically\n",
    "    transformers = []\n",
    "    if log_transform_cols:\n",
    "        transformers.append((\"log_num\", log_numeric_pipeline, log_transform_cols))\n",
    "    if standard_numeric_cols:\n",
    "        transformers.append((\"std_num\", standard_numeric_pipeline, standard_numeric_cols))\n",
    "    if categorical_cols:\n",
    "        transformers.append((\"cat\", categorical_pipeline, categorical_cols))\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=transformers,\n",
    "        remainder=\"drop\",\n",
    "        verbose_feature_names_out=False\n",
    "    )\n",
    "    \n",
    "    # Full model pipeline with ElasticNet\n",
    "    model = Pipeline(steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"classifier\", LogisticRegression(\n",
    "            penalty=\"elasticnet\",\n",
    "            solver=\"saga\",          # Only solver that supports elasticnet\n",
    "            l1_ratio=0.5,           # Balance between L1 and L2\n",
    "            C=1.0,                  # Regularization strength (will tune)\n",
    "            max_iter=5000,          # saga needs more iterations\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    feature_groups = {\n",
    "        \"log_numeric\": log_transform_cols,\n",
    "        \"standard_numeric\": standard_numeric_cols,\n",
    "        \"categorical\": categorical_cols,\n",
    "    }\n",
    "    \n",
    "    return model, feature_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "376f2739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered features: 47 total\n",
      "  Numeric: 45\n",
      "  Categorical: 2\n",
      "\n",
      "Numeric features: ['total_spend', 'rev_ticket', 'prod_ticket', 'n_cogo', 'cogo_rev', 'online_channel_ratio', 'price_sens_colr', 'discount_ratio', 'cat_Wijn_Stillewijnen_RAYON', 'wine_affinity_spend', 'wine_affinity_ratio', 'premium_ratio', 'SOW_colr', 'SOW_!', 'cat_Babyluiers_neg_flag', 'cat_Ber_Ger_DVPortioneerbaar_neg_flag', 'cat_Ber_Ger_VersMaaltijdsalades_neg_flag', 'cat_Bier_Genietbieren_neg_flag', 'cat_Bot_Mar_Boter_neg_flag', 'cat_BroodKorthoudbaar_neg_flag', 'cat_Chips_neg_flag', 'cat_ColruytMobile_Toestellen_neg_flag', 'cat_EleKtroKeuken_neg_flag', 'cat_Houtpelletskolen_briketten_neg_flag', 'cat_Incontinentie_luiers_neg_flag', 'cat_KaasSeizoenskazen_neg_flag', 'cat_KoudeSauzen_neg_flag', 'cat_MelkKarnemelk_neg_flag', 'cat_Notengedroogdfruit_groenten_neg_flag', 'cat_ParfumerieEHBO_neg_flag', 'cat_Tapas_neg_flag', 'cat_Textiel_Herenondergoed_neg_flag', 'cat_Textiel_Pantys_neg_flag', 'cat_VNCBGBereidegerechten_neg_flag', 'cat_VNCBerBurgers_neg_flag', 'cat_VNCCharBHWildpasteien_neg_flag', 'cat_VNCFSalades_neg_flag', 'cat_VNCGevgeheel_neg_flag', 'cat_VNCRest_neg_flag', 'cat_VerseKaasFruitkazen_neg_flag', 'cat_VisGerookt_neg_flag', 'cat_VisVerseSchelpdieren_neg_flag', 'cat_Wijn_Stillewijnen_RAYON_neg_flag', 'cat_Zomerspeelgoed_neg_flag', 'cat_bbqfoodevent_neg_flag']\n",
      "Categorical features: ['HOUSEHOLDTYPOLOGY', 'SOW_type_colr']\n",
      "\n",
      "============================================================\n",
      "FEATURE GROUPS\n",
      "============================================================\n",
      "\n",
      "LOG_NUMERIC (5):\n",
      "   total_spend\n",
      "   cogo_rev\n",
      "   cat_Wijn_Stillewijnen_RAYON\n",
      "   wine_affinity_spend\n",
      "   rev_ticket\n",
      "\n",
      "STANDARD_NUMERIC (40):\n",
      "   prod_ticket\n",
      "   n_cogo\n",
      "   online_channel_ratio\n",
      "   price_sens_colr\n",
      "   discount_ratio\n",
      "   wine_affinity_ratio\n",
      "   premium_ratio\n",
      "   SOW_colr\n",
      "   SOW_!\n",
      "   cat_Babyluiers_neg_flag\n",
      "   cat_Ber_Ger_DVPortioneerbaar_neg_flag\n",
      "   cat_Ber_Ger_VersMaaltijdsalades_neg_flag\n",
      "   cat_Bier_Genietbieren_neg_flag\n",
      "   cat_Bot_Mar_Boter_neg_flag\n",
      "   cat_BroodKorthoudbaar_neg_flag\n",
      "   cat_Chips_neg_flag\n",
      "   cat_ColruytMobile_Toestellen_neg_flag\n",
      "   cat_EleKtroKeuken_neg_flag\n",
      "   cat_Houtpelletskolen_briketten_neg_flag\n",
      "   cat_Incontinentie_luiers_neg_flag\n",
      "   cat_KaasSeizoenskazen_neg_flag\n",
      "   cat_KoudeSauzen_neg_flag\n",
      "   cat_MelkKarnemelk_neg_flag\n",
      "   cat_Notengedroogdfruit_groenten_neg_flag\n",
      "   cat_ParfumerieEHBO_neg_flag\n",
      "   cat_Tapas_neg_flag\n",
      "   cat_Textiel_Herenondergoed_neg_flag\n",
      "   cat_Textiel_Pantys_neg_flag\n",
      "   cat_VNCBGBereidegerechten_neg_flag\n",
      "   cat_VNCBerBurgers_neg_flag\n",
      "   cat_VNCCharBHWildpasteien_neg_flag\n",
      "   cat_VNCFSalades_neg_flag\n",
      "   cat_VNCGevgeheel_neg_flag\n",
      "   cat_VNCRest_neg_flag\n",
      "   cat_VerseKaasFruitkazen_neg_flag\n",
      "   cat_VisGerookt_neg_flag\n",
      "   cat_VisVerseSchelpdieren_neg_flag\n",
      "   cat_Wijn_Stillewijnen_RAYON_neg_flag\n",
      "   cat_Zomerspeelgoed_neg_flag\n",
      "   cat_bbqfoodevent_neg_flag\n",
      "\n",
      "CATEGORICAL (2):\n",
      "   HOUSEHOLDTYPOLOGY\n",
      "   SOW_type_colr\n"
     ]
    }
   ],
   "source": [
    "# Apply feature engineering to train and test sets (ONCE)\n",
    "X_train_eng, num_cols, cat_cols = final_features(X_train)\n",
    "X_test_eng, _, _ = final_features(X_test)\n",
    "\n",
    "# Ensure test has same columns as train (missing columns -> fill with 0)\n",
    "X_test_eng = X_test_eng.reindex(columns=X_train_eng.columns, fill_value=0)\n",
    "\n",
    "print(f\"Engineered features: {X_train_eng.shape[1]} total\")\n",
    "print(f\"  Numeric: {len(num_cols)}\")\n",
    "print(f\"  Categorical: {len(cat_cols)}\")\n",
    "print(f\"\\nNumeric features: {num_cols}\")\n",
    "print(f\"Categorical features: {cat_cols}\")\n",
    "\n",
    "# Build the pipeline (pass feature lists, NOT raw data)\n",
    "gold_model, feature_groups = finalpipeline(num_cols, cat_cols)\n",
    "\n",
    "# Show feature groups\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE GROUPS\")\n",
    "print(\"=\"*60)\n",
    "for k, v in feature_groups.items():\n",
    "    print(f\"\\n{k.upper()} ({len(v)}):\")\n",
    "    for c in v:\n",
    "        print(\"  \", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "245fac24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: STABILITY CHECK (Fixed Parameters)\n",
      "Running CV with fixed params to check variance before tuning...\n",
      "\n",
      "Average Precision: 0.4097 ± 0.0102\n",
      "F1 Score:          0.3124 ± 0.0020\n",
      "Precision:         0.1924 ± 0.0012\n",
      "Recall:            0.8290 ± 0.0100\n",
      "\n",
      " Model is VERY STABLE (std < 0.03)\n",
      "\n",
      "Average Precision: 0.4097 ± 0.0102\n",
      "F1 Score:          0.3124 ± 0.0020\n",
      "Precision:         0.1924 ± 0.0012\n",
      "Recall:            0.8290 ± 0.0100\n",
      "\n",
      " Model is VERY STABLE (std < 0.03)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer, average_precision_score, precision_recall_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "#  STABILITY CHECK ( fixed params first because if model is not stable, tuning is pointless)\n",
    "\n",
    "\n",
    "print(\"STEP 1: STABILITY CHECK (Fixed Parameters)\")\n",
    "print(\"Running CV with fixed params to check variance before tuning...\")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Use average_precision (better for imbalanced data than F1 becuase it considers ranking along with other metrics)\n",
    "stability_scores = cross_validate(\n",
    "    gold_model,\n",
    "    X_train_eng,\n",
    "    y_train,\n",
    "    cv=cv,\n",
    "    scoring={\n",
    "        'average_precision': 'average_precision',\n",
    "        'f1': 'f1',\n",
    "        'precision': 'precision',\n",
    "        'recall': 'recall'\n",
    "    },\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(f\"\\nAverage Precision: {stability_scores['test_average_precision'].mean():.4f} ± {stability_scores['test_average_precision'].std():.4f}\")\n",
    "print(f\"F1 Score:          {stability_scores['test_f1'].mean():.4f} ± {stability_scores['test_f1'].std():.4f}\")\n",
    "print(f\"Precision:         {stability_scores['test_precision'].mean():.4f} ± {stability_scores['test_precision'].std():.4f}\")\n",
    "print(f\"Recall:            {stability_scores['test_recall'].mean():.4f} ± {stability_scores['test_recall'].std():.4f}\")\n",
    "\n",
    "# Check if variance is acceptable (std < 0.05 is good)\n",
    "ap_std = stability_scores['test_average_precision'].std()\n",
    "if ap_std < 0.03:\n",
    "    print(\"\\n Model is VERY STABLE (std < 0.03)\")\n",
    "elif ap_std < 0.05:\n",
    "    print(\"\\n Model is STABLE (std < 0.05)\")\n",
    "else:\n",
    "    print(f\"\\n Model has HIGH VARIANCE (std = {ap_std:.4f})  proceed with caution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e8e5468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2: COEFFICIENT STABILITY ACROSS FOLDS\n",
      "\n",
      "Total features: 71\n",
      "Stable features (same sign ≥80% folds): 67\n",
      "Unstable features (sign flips): 4\n",
      "\n",
      " Unstable features:\n",
      "   SOW_!: stable in 60% of folds\n",
      "   cat_Bier_Genietbieren_neg_flag: stable in 60% of folds\n",
      "   HOUSEHOLDTYPOLOGY_f_HHnochild_35_54: stable in 40% of folds\n",
      "   HOUSEHOLDTYPOLOGY_k_HHchild_oldest_13_17: stable in 40% of folds\n",
      "\n",
      "------------------------------------------------------------\n",
      "TOP 10 FEATURES BY MEAN |COEFFICIENT|\n",
      "------------------------------------------------------------\n",
      "  + rev_ticket                               coef=+1.981 ± 0.019\n",
      "  + wine_affinity_spend                      coef=+1.762 ± 0.047\n",
      "  - SOW_type_colr_SOW00-10                   coef=-1.331 ± 0.052\n",
      "  + SOW_type_colr_Outlier_fr                 coef=+1.301 ± 0.068\n",
      "  - discount_ratio                           coef=-1.101 ± 0.091\n",
      "  - SOW_type_colr_SOW10-20                   coef=-1.053 ± 0.048\n",
      "  - total_spend                              coef=-1.037 ± 0.039\n",
      "  - prod_ticket                              coef=-0.829 ± 0.011\n",
      "  - SOW_type_colr_SOW20-30                   coef=-0.762 ± 0.037\n",
      "  - wine_affinity_ratio                      coef=-0.668 ± 0.009\n",
      "\n",
      "Total features: 71\n",
      "Stable features (same sign ≥80% folds): 67\n",
      "Unstable features (sign flips): 4\n",
      "\n",
      " Unstable features:\n",
      "   SOW_!: stable in 60% of folds\n",
      "   cat_Bier_Genietbieren_neg_flag: stable in 60% of folds\n",
      "   HOUSEHOLDTYPOLOGY_f_HHnochild_35_54: stable in 40% of folds\n",
      "   HOUSEHOLDTYPOLOGY_k_HHchild_oldest_13_17: stable in 40% of folds\n",
      "\n",
      "------------------------------------------------------------\n",
      "TOP 10 FEATURES BY MEAN |COEFFICIENT|\n",
      "------------------------------------------------------------\n",
      "  + rev_ticket                               coef=+1.981 ± 0.019\n",
      "  + wine_affinity_spend                      coef=+1.762 ± 0.047\n",
      "  - SOW_type_colr_SOW00-10                   coef=-1.331 ± 0.052\n",
      "  + SOW_type_colr_Outlier_fr                 coef=+1.301 ± 0.068\n",
      "  - discount_ratio                           coef=-1.101 ± 0.091\n",
      "  - SOW_type_colr_SOW10-20                   coef=-1.053 ± 0.048\n",
      "  - total_spend                              coef=-1.037 ± 0.039\n",
      "  - prod_ticket                              coef=-0.829 ± 0.011\n",
      "  - SOW_type_colr_SOW20-30                   coef=-0.762 ± 0.037\n",
      "  - wine_affinity_ratio                      coef=-0.668 ± 0.009\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  COEFFICIENT STABILITY ANALYSIS(we are checking if coeffs are stable across folds by training model on each fold and collecting coeffs) \n",
    "#if model is not stable, we cannot interpret coeffs \n",
    "\n",
    "print(\"STEP 2: COEFFICIENT STABILITY ACROSS FOLDS\")\n",
    "\n",
    "\n",
    "from sklearn.base import clone\n",
    "#we have this function to get feature names from pipeline becuase we have custom transformers so sklearn cannot infer names automatically\n",
    "def get_feature_names(model, feature_groups):\n",
    "    \"\"\"Simple helper to get feature names from our pipeline.\"\"\"\n",
    "    names = feature_groups['log_numeric'] + feature_groups['standard_numeric']\n",
    "    # Add OHE categories because they expand into multiple features so we need to get their names\n",
    "    ohe = model.named_steps['preprocess'].named_transformers_['cat'].named_steps['ohe']\n",
    "    for col_idx, col in enumerate(feature_groups['categorical']):\n",
    "        for cat in ohe.categories_[col_idx]:\n",
    "            names.append(f\"{col}_{cat}\")\n",
    "    return names\n",
    "\n",
    "# Collect coefficients from each fold\n",
    "fold_coefs = []\n",
    "fold_feature_names = None\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X_train_eng, y_train)):\n",
    "    X_fold_train = X_train_eng.iloc[train_idx]\n",
    "    y_fold_train = y_train.iloc[train_idx]\n",
    "    \n",
    "    fold_model = clone(gold_model)\n",
    "    fold_model.fit(X_fold_train, y_fold_train)\n",
    "    fold_coefs.append(fold_model.named_steps['classifier'].coef_[0])\n",
    "    \n",
    "    if fold_feature_names is None:\n",
    "        fold_feature_names = get_feature_names(fold_model, feature_groups)\n",
    "\n",
    "fold_coefs = np.array(fold_coefs)\n",
    "\n",
    "# Check sign stability (because features with signs that change a lot indicate instability)\n",
    "sign_stability = (np.sign(fold_coefs) == np.sign(fold_coefs.mean(axis=0))).mean(axis=0)\n",
    "unstable_mask = sign_stability < 0.8\n",
    "\n",
    "print(f\"\\nTotal features: {len(fold_feature_names)}\")\n",
    "print(f\"Stable features (same sign ≥80% folds): {(~unstable_mask).sum()}\")\n",
    "print(f\"Unstable features (sign flips): {unstable_mask.sum()}\")\n",
    "\n",
    "if unstable_mask.any():\n",
    "    print(\"\\n Unstable features:\")\n",
    "    for name, stab in zip(fold_feature_names, sign_stability):\n",
    "        if stab < 0.8:\n",
    "            print(f\"   {name}: stable in {stab*100:.0f}% of folds\")\n",
    "else:\n",
    "    print(\"\\n All features have stable coefficient signs!\")\n",
    "\n",
    "# Top features by mean absolute coefficient (because magnitude matters for impact)\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"TOP 10 FEATURES BY MEAN |COEFFICIENT|\")\n",
    "print(\"-\"*60)\n",
    "mean_coefs = fold_coefs.mean(axis=0)\n",
    "std_coefs = fold_coefs.std(axis=0)\n",
    "top_idx = np.argsort(np.abs(mean_coefs))[-10:][::-1] \n",
    "\n",
    "for idx in top_idx:\n",
    "    sign = \"+\" if mean_coefs[idx] > 0 else \"-\"\n",
    "    print(f\"  {sign} {fold_feature_names[idx]:40s} coef={mean_coefs[idx]:+.3f} ± {std_coefs[idx]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98aa4d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 3: HYPOTHESIS-DRIVEN TUNING\n",
      "\n",
      "Grid size: 12 combinations\n",
      "Scoring: average_precision (better for imbalanced marketing problems)\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Best Average Precision: 0.4097\n",
      "   Best C: 2.0\n",
      "   Best l1_ratio: 0.3\n",
      "\n",
      " Improvement from tuning: +0.01%\n",
      "   → Minimal improvement. Default params are fine.\n",
      "\n",
      "Best Average Precision: 0.4097\n",
      "   Best C: 2.0\n",
      "   Best l1_ratio: 0.3\n",
      "\n",
      " Improvement from tuning: +0.01%\n",
      "   → Minimal improvement. Default params are fine.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# STEP 3: SMALL HYPOTHESIS-DRIVEN GRID SEARCH\n",
    "\n",
    "print(\"STEP 3: HYPOTHESIS-DRIVEN TUNING\")\n",
    "#we didnt do gridsearch cv over large grid becuase it can lead to overfitting on cv folds and also we have stability check already done\n",
    "# small grid, hypothesis-driven, not slot machine\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Small, focused grid (not 200 combinations as it leads to overfitting on CV folds)\n",
    "# hypothesis: ElasticNet with moderate regularization should work best\n",
    "param_grid = {\n",
    "    'classifier__C': [0.1, 0.5, 1.0, 2.0],      # Regularization strength (small c = strong regularization, simple model, we used 1.0 as default)\n",
    "    'classifier__l1_ratio': [0.3, 0.5, 0.7],    # L1 vs L2 balance (bigger ratio => many useless features zeroed out, we used 0.5 as default)\n",
    "}\n",
    "\n",
    "print(f\"\\nGrid size: {len(param_grid['classifier__C']) * len(param_grid['classifier__l1_ratio'])} combinations\")\n",
    "print(\"Scoring: average_precision (better for imbalanced marketing problems)\")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=gold_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='average_precision',  #  choice for imbalanced data as it considers ranking\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_eng, y_train)\n",
    "\n",
    "print(f\"\\nBest Average Precision: {grid_search.best_score_:.4f}\")\n",
    "print(f\"   Best C: {grid_search.best_params_['classifier__C']}\")\n",
    "print(f\"   Best l1_ratio: {grid_search.best_params_['classifier__l1_ratio']}\")\n",
    "\n",
    "# Compare default vs tuned\n",
    "baseline_ap = stability_scores['test_average_precision'].mean()\n",
    "tuned_ap = grid_search.best_score_\n",
    "improvement = (tuned_ap - baseline_ap) / baseline_ap * 100\n",
    "\n",
    "print(f\"\\n Improvement from tuning: {improvement:+.2f}%\")\n",
    "if improvement < 2:\n",
    "    print(\"   → Minimal improvement. Default params are fine.\")\n",
    "elif improvement < 5:\n",
    "    print(\"   → Modest improvement. Use tuned params.\")\n",
    "else:\n",
    "    print(\"   → Significant improvement. Tuning was worthwhile.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8592da54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 4: THRESHOLD TUNING\n",
      "\n",
      "Threshold Analysis:\n",
      "------------------------------------------------------------\n",
      "Max F1 threshold:           0.829 (F1=0.439)\n",
      "Max Recall @ Precision≥70%: 0.986 (Recall=0.126)\n",
      "Max Recall @ Precision≥50%: 0.914 (Recall=0.328)\n",
      "Max Recall @ Precision≥30%: 0.722 (Recall=0.628)\n",
      "\n",
      "Using threshold: 0.829 (Max F1 objective)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# STEP 4: THRESHOLD TUNING (we tune threshold, not just weights as we are dealing with probabilities)\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, classification_report, confusion_matrix\n",
    "\n",
    "print(\"STEP 4: THRESHOLD TUNING\")\n",
    "\n",
    "\n",
    "\n",
    "# Get best model and predict probabilities\n",
    "best_model = grid_search.best_estimator_\n",
    "y_proba = best_model.predict_proba(X_test_eng)[:, 1]\n",
    "\n",
    "# Calculate precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "# Find optimal threshold for different business objectives\n",
    "print(\"\\nThreshold Analysis:\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "#  Maximize F1 , becuase balnces precision and recall\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "best_f1_idx = np.argmax(f1_scores[:-1])  # exclude last element\n",
    "best_f1_threshold = thresholds[best_f1_idx]\n",
    "print(f\"Max F1 threshold:           {best_f1_threshold:.3f} (F1={f1_scores[best_f1_idx]:.3f})\")\n",
    "\n",
    "# Recall @ Precision >= 0.7 (realistic for marketing, as good precision to avoid waste)\n",
    "mask_p70 = precision[:-1] >= 0.7\n",
    "if mask_p70.any():\n",
    "    best_recall_at_p70 = recall[:-1][mask_p70].max()\n",
    "    idx_p70 = np.where((recall[:-1] == best_recall_at_p70) & mask_p70)[0][0]\n",
    "    threshold_p70 = thresholds[idx_p70]\n",
    "    print(f\"Max Recall @ Precision≥70%: {threshold_p70:.3f} (Recall={best_recall_at_p70:.3f})\")\n",
    "else:\n",
    "    print(\"Max Recall @ Precision≥70%: Not achievable\")\n",
    "# Recall @ Precision >= 0.5 (balanced)\n",
    "mask_p50 = precision[:-1] >= 0.5\n",
    "if mask_p50.any():\n",
    "    best_recall_at_p50 = recall[:-1][mask_p50].max()\n",
    "    idx_p50 = np.where((recall[:-1] == best_recall_at_p50) & mask_p50)[0][0]\n",
    "    threshold_p50 = thresholds[idx_p50]\n",
    "    print(f\"Max Recall @ Precision≥50%: {threshold_p50:.3f} (Recall={best_recall_at_p50:.3f})\")\n",
    "else:\n",
    "    print(\"Max Recall @ Precision≥50%: Not achievable\")\n",
    "\n",
    "# Objective 4: Recall @ Precision >= 0.3 (broader reach)\n",
    "mask_p30 = precision[:-1] >= 0.3\n",
    "if mask_p30.any():\n",
    "    best_recall_at_p30 = recall[:-1][mask_p30].max()\n",
    "    idx_p30 = np.where((recall[:-1] == best_recall_at_p30) & mask_p30)[0][0]\n",
    "    threshold_p30 = thresholds[idx_p30]\n",
    "    print(f\"Max Recall @ Precision≥30%: {threshold_p30:.3f} (Recall={best_recall_at_p30:.3f})\")\n",
    "else:\n",
    "    print(\"Max Recall @ Precision≥30%: Not achievable\")\n",
    "\n",
    "# Use best F1 threshold for final evaluation as default (we can be changed based on business needs)\n",
    "CHOSEN_THRESHOLD = best_f1_threshold\n",
    "print(f\"\\nUsing threshold: {CHOSEN_THRESHOLD:.3f} (Max F1 objective)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1af3d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 5: FINAL TEST SET EVALUATION\n",
      "\n",
      "Classification Report (Tuned Threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " No Highbrow       0.97      0.96      0.97     38008\n",
      "    Highbrow       0.39      0.50      0.44      1992\n",
      "\n",
      "    accuracy                           0.94     40000\n",
      "   macro avg       0.68      0.73      0.70     40000\n",
      "weighted avg       0.94      0.94      0.94     40000\n",
      "\n",
      "\n",
      "Confusion Matrix (Tuned Threshold):\n",
      "                    Predicted\n",
      "                No         Yes\n",
      "Actual No    36486        1522\n",
      "Actual Yes    1003         989\n",
      "\n",
      " Business Metrics:\n",
      "   True Positives (correctly identified buyers): 989\n",
      "   False Positives (wasted marketing): 1522\n",
      "   False Negatives (missed buyers): 1003\n",
      "   True Negatives (correctly ignored): 36486\n",
      "\n",
      "    If you target 2511 customers:\n",
      "      → 989 will buy (39.4% hit rate)\n",
      "      → 1522 won't buy (wasted effort)\n",
      "\n",
      "------------------------------------------------------------\n",
      " THRESHOLD COMPARISON:\n",
      "------------------------------------------------------------\n",
      "Default (0.50): Precision=0.190, Recall=0.823, TP=1640, FP=6988\n",
      "Tuned (0.83):   Precision=0.394, Recall=0.496, TP=989, FP=1522\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# STEP 5: FINAL TEST SET EVALUATION\n",
    "\n",
    "\n",
    "print(\"STEP 5: FINAL TEST SET EVALUATION\")\n",
    "\n",
    "\n",
    "# Predictions with tuned threshold\n",
    "y_pred_tuned = (y_proba >= CHOSEN_THRESHOLD).astype(int)\n",
    "y_pred_default = best_model.predict(X_test_eng)  # default 0.5 threshold\n",
    "\n",
    "print(\"\\nClassification Report (Tuned Threshold):\")\n",
    "print(classification_report(y_test, y_pred_tuned, target_names=[\"No Highbrow\", \"Highbrow\"]))\n",
    "\n",
    "print(\"\\nConfusion Matrix (Tuned Threshold):\")\n",
    "cm = confusion_matrix(y_test, y_pred_tuned)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"                    Predicted\")\n",
    "print(f\"                No         Yes\")\n",
    "print(f\"Actual No    {tn:5d}       {fp:5d}\")\n",
    "print(f\"Actual Yes   {fn:5d}       {tp:5d}\")\n",
    "\n",
    "print(\"\\n Business Metrics:\")\n",
    "print(f\"   True Positives (correctly identified buyers): {tp}\")\n",
    "print(f\"   False Positives (wasted marketing): {fp}\")\n",
    "print(f\"   False Negatives (missed buyers): {fn}\")\n",
    "print(f\"   True Negatives (correctly ignored): {tn}\")\n",
    "\n",
    "# Marketing efficiency \n",
    "if tp + fp > 0:\n",
    "    precision_val = tp / (tp + fp)\n",
    "    print(f\"\\n    If you target {tp + fp} customers:\")\n",
    "    print(f\"      → {tp} will buy ({precision_val*100:.1f}% hit rate)\")\n",
    "    print(f\"      → {fp} won't buy (wasted effort)\")\n",
    "\n",
    "# Compare default vs tuned threshold\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\" THRESHOLD COMPARISON:\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "cm_default = confusion_matrix(y_test, y_pred_default)\n",
    "tn_d, fp_d, fn_d, tp_d = cm_default.ravel()\n",
    "\n",
    "print(f\"Default (0.50): Precision={tp_d/(tp_d+fp_d):.3f}, Recall={tp_d/(tp_d+fn_d):.3f}, TP={tp_d}, FP={fp_d}\")\n",
    "print(f\"Tuned ({CHOSEN_THRESHOLD:.2f}):   Precision={precision_val:.3f}, Recall={tp/(tp+fn):.3f}, TP={tp}, FP={fp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c92583c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 6: FEATURE IMPORTANCE INTERPRETATION\n",
      "\n",
      "Total features: 71\n",
      "\n",
      " TOP 15 FEATURES BY IMPORTANCE:\n",
      "------------------------------------------------------------\n",
      "  ↑ rev_ticket                               +1.9807\n",
      "  ↑ wine_affinity_spend                      +1.7631\n",
      "  ↓ SOW_type_colr_SOW00-10                   -1.3381\n",
      "  ↑ SOW_type_colr_Outlier_fr                 +1.3056\n",
      "  ↓ discount_ratio                           -1.0945\n",
      "  ↓ SOW_type_colr_SOW10-20                   -1.0591\n",
      "  ↓ total_spend                              -1.0371\n",
      "  ↓ prod_ticket                              -0.8288\n",
      "  ↓ SOW_type_colr_SOW20-30                   -0.7674\n",
      "  ↓ wine_affinity_ratio                      -0.6687\n",
      "  ↑ SOW_type_colr_Outlier_om                 +0.6647\n",
      "  ↓ HOUSEHOLDTYPOLOGY_i_HHchild_oldest_0_5   -0.5797\n",
      "  ↓ HOUSEHOLDTYPOLOGY_a_Single_18_34         -0.4993\n",
      "  ↑ HOUSEHOLDTYPOLOGY_e_HHnochild_18_34      +0.4738\n",
      "  ↓ SOW_type_colr_SOW30-40                   -0.4629\n",
      "\n",
      " INTERPRETATION:\n",
      " Positive = INCREASES likelihood of buying highbrow wine\n",
      "Negative = DECREASES likelihood of buying highbrow wine\n",
      "\n",
      " KEY POSITIVE DRIVERS:\n",
      "   • rev_ticket\n",
      "   • wine_affinity_spend\n",
      "   • SOW_type_colr_Outlier_fr\n",
      "   • SOW_type_colr_Outlier_om\n",
      "   • HOUSEHOLDTYPOLOGY_e_HHnochild_18_34\n",
      "\n",
      " KEY NEGATIVE DRIVERS:\n",
      "   • SOW_type_colr_SOW00-10\n",
      "   • discount_ratio\n",
      "   • SOW_type_colr_SOW10-20\n",
      "   • total_spend\n",
      "   • prod_ticket\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# STEP 6: FEATURE IMPORTANCE \n",
    "\n",
    "\n",
    "print(\"STEP 6: FEATURE IMPORTANCE INTERPRETATION\")\n",
    "\n",
    "\n",
    "# Get feature names and coefficients\n",
    "feature_names = get_feature_names(best_model, feature_groups)\n",
    "coefs = best_model.named_steps['classifier'].coef_[0]\n",
    "\n",
    "print(f\"\\nTotal features: {len(coefs)}\")\n",
    "\n",
    "# Create sorted DataFrame\n",
    "coef_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coefficient': coefs,\n",
    "}).assign(abs_coef=lambda x: np.abs(x.coefficient)).sort_values('abs_coef', ascending=False)\n",
    "\n",
    "print(\"\\n TOP 15 FEATURES BY IMPORTANCE:\")\n",
    "print(\"-\"*60)\n",
    "for _, row in coef_df.head(15).iterrows():\n",
    "    direction = \"↑\" if row['coefficient'] > 0 else \"↓\"\n",
    "    print(f\"  {direction} {row['feature']:40s} {row['coefficient']:+.4f}\")\n",
    "\n",
    "print(\"\\n INTERPRETATION:\")\n",
    "print(\" Positive = INCREASES likelihood of buying highbrow wine\")\n",
    "print(\"Negative = DECREASES likelihood of buying highbrow wine\")\n",
    "\n",
    "print(\"\\n KEY POSITIVE DRIVERS:\")\n",
    "for f in coef_df[coef_df['coefficient'] > 0].head(5)['feature']:\n",
    "    print(f\"   • {f}\")\n",
    "\n",
    "print(\"\\n KEY NEGATIVE DRIVERS:\")\n",
    "for f in coef_df[coef_df['coefficient'] < 0].head(5)['feature']:\n",
    "    print(f\"   • {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b892e513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   predicted_prob  bought_highbrow_wines\n",
      "0        0.004811                      0\n",
      "1        0.702256                      0\n",
      "2        0.080378                      0\n",
      "3        0.466862                      0\n",
      "4        0.071346                      0\n"
     ]
    }
   ],
   "source": [
    "#Using 2017 datset\n",
    "# language: python\n",
    "# filepath: c:\\Users\\srd9cxl\\OneDrive - Colruyt Group NV\\Desktop\\highbrow wines case\\Highbrow-wines-case-predictive-modelling-\\entirepipieline.ipynb\n",
    "\n",
    "# 1.inference data\n",
    "inference_df = pd.read_csv(\"C:\\\\Users\\\\srd9cxl\\\\OneDrive - Colruyt Group NV\\\\Desktop\\\\highbrow wines case\\\\Highbrow-wines-case-predictive-modelling-\\\\data_2017_new.csv\")\n",
    "\n",
    "# 2. Feature engineering\n",
    "X_inf_eng, _, _ = final_features(inference_df)\n",
    "\n",
    "# 3. Align columns with training data\n",
    "X_inf_eng = X_inf_eng.reindex(columns=X_train_eng.columns, fill_value=0)\n",
    "\n",
    "# 4. Predict probabilities and classes\n",
    "proba = best_model.predict_proba(X_inf_eng)[:, 1]\n",
    "pred_class = (proba >= CHOSEN_THRESHOLD).astype(int)\n",
    "\n",
    "#attaching predictions to inference_df\n",
    "inference_df[\"predicted_prob\"] = proba\n",
    "inference_df[\"bought_highbrow_wines\"] = pred_class\n",
    "\n",
    "# 6. Save or inspect results\n",
    "inference_df.to_csv(\"2017_with_predictions.csv\", index=False)\n",
    "print(inference_df[[\"predicted_prob\", \"bought_highbrow_wines\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27265b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6693bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a2ec01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328c7e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.2\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
