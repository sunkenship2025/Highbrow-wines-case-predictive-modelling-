{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7831289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    OneHotEncoder,\n",
    "    FunctionTransformer\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69205a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4fd966bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load our data\n",
    "data = pd.read_csv('data_2016.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "243a522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets train test split\n",
    "X = data.drop(columns=['bought_highbrow_wines'])\n",
    "y = data['bought_highbrow_wines']\n",
    "#lets drop x values whose y is nan\n",
    "X = X.loc[y.dropna().index]\n",
    "y = y.dropna()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ae08a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # numeric coercion (NO filling here)\n",
    "    num_cols = [c for c in df.columns if c.startswith(\"cat_\")] + [\n",
    "        \"rev_ticket\", \"prod_ticket\", \"n_cogo\", \"cogo_rev\",\n",
    "        \"total_discount\", \"price_sens_colr\", \"SOW_colr\"\n",
    "    ]\n",
    "    num_cols = [c for c in num_cols if c in df.columns]\n",
    "\n",
    "    for c in num_cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    # SOW normalization + flag\n",
    "    if \"SOW_type_colr\" in df.columns:\n",
    "        df[\"SOW_!\"] = (df[\"SOW_type_colr\"] == \"!\").astype(int)\n",
    "        df[\"SOW_type_colr\"] = (\n",
    "            df[\"SOW_type_colr\"]\n",
    "            .fillna(\"unknown\")\n",
    "            .replace(\"!\", \"unknown\")\n",
    "        )\n",
    "\n",
    "    # Household normalization\n",
    "    if \"HOUSEHOLDTYPOLOGY\" in df.columns:\n",
    "        df[\"HOUSEHOLDTYPOLOGY\"] = (\n",
    "            df[\"HOUSEHOLDTYPOLOGY\"]\n",
    "            .fillna(\"unknown\")\n",
    "            .replace(\"!\", \"unknown\")\n",
    "        )\n",
    "\n",
    "    # Negative value flags\n",
    "    for c in [col for col in df.columns if col.startswith(\"cat_\")]:\n",
    "        negs = df[c] < 0\n",
    "        df[f\"{c}_neg_flag\"] = negs.astype(int)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11415cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ClipLog(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        arr = np.array(X, dtype=float, copy=True)\n",
    "        arr[arr < 0] = 0\n",
    "        return np.log1p(arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b402dc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #making categories \n",
    "# # Spend / turnover-like features\n",
    "# spend_cols = [col for col in X_train.columns if col.startswith(\"cat_\")] + [\n",
    "#     \"cogo_rev\",\n",
    "#     \"total_discount\",\n",
    "#     \"rev_ticket\"\n",
    "# ]\n",
    "\n",
    "# # Count-like features (can also be scaled)\n",
    "# count_cols = [\n",
    "#     \"prod_ticket\",\n",
    "#     \"n_cogo\"\n",
    "# ]\n",
    "\n",
    "# # Other numeric features\n",
    "# other_numeric_cols = [\n",
    "#     \"price_sens_colr\",\n",
    "#     \"SOW_colr\"\n",
    "# ]\n",
    "\n",
    "# numeric_cols = spend_cols + count_cols + other_numeric_cols\n",
    "\n",
    "# categorical_cols = [\n",
    "#     \"HOUSEHOLDTYPOLOGY\",\n",
    "#     \"SOW_type_colr\"\n",
    "# ]\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def infer_feature_groups(df: pd.DataFrame,\n",
    "                          skew_thresh=1.0,\n",
    "                          range_ratio_thresh=20):\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "    # ---- Binary (0/1) ----\n",
    "    binary_cols = []\n",
    "    for c in numeric_cols:\n",
    "        vals = df[c].dropna().unique()\n",
    "        if len(vals) <= 2 and set(vals).issubset({0, 1}):\n",
    "            binary_cols.append(c)\n",
    "\n",
    "    # ---- Bounded [0,1] but not binary we want to keep ----\n",
    "    bounded_cols = []\n",
    "    for c in numeric_cols:\n",
    "        if c in binary_cols:\n",
    "            continue\n",
    "        col = df[c].dropna()\n",
    "        if len(col) and col.min() >= 0 and col.max() <= 1:\n",
    "            bounded_cols.append(c)\n",
    "\n",
    "    log_cols = [\n",
    "        c for c in numeric_cols\n",
    "        if c not in binary_cols\n",
    "        and c not in bounded_cols\n",
    "        \n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"log_numeric\": log_cols,\n",
    "        \"binary\": binary_cols,\n",
    "        \"categorical\": categorical_cols,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62f9fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalpipeline(X_train: pd.DataFrame):\n",
    "    groups = infer_feature_groups(X_train)\n",
    "\n",
    "    \n",
    "    log_numeric_pipeline = Pipeline([\n",
    "        (\"impute\", SimpleImputer(strategy=\"constant\", fill_value=0)),\n",
    "        (\"clip_log\", ClipLog()),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    bounded_numeric_pipeline = Pipeline([\n",
    "        (\"impute\", SimpleImputer(strategy=\"constant\", fill_value=0)),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "    binary_pipeline = Pipeline([\n",
    "        (\"impute\", SimpleImputer(strategy=\"constant\", fill_value=0))\n",
    "    ])\n",
    "#this try except isfordifferent sklearn versions\n",
    "    try:\n",
    "        ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    except TypeError:\n",
    "        ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "    categorical_pipeline = Pipeline([\n",
    "        (\"impute\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "        (\"ohe\", ohe)\n",
    "    ])\n",
    "\n",
    "   #column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"log_num\", log_numeric_pipeline, groups[\"log_numeric\"]),\n",
    "\n",
    "            (\"bin\", binary_pipeline, groups[\"binary\"]),\n",
    "            (\"cat\", categorical_pipeline, groups[\"categorical\"]),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "        verbose_feature_names_out=False\n",
    "    )\n",
    "\n",
    "   #model\n",
    "    model = Pipeline(steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"classifier\", LogisticRegression(\n",
    "            max_iter=1000,\n",
    "            class_weight=\"balanced\",\n",
    "            solver=\"lbfgs\",\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    return model, groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "376f2739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG_NUMERIC (8):\n",
      "   cat_Bot_Mar_Boter\n",
      "   cat_Chips\n",
      "   cat_KoudeSauzen\n",
      "   cat_Notengedroogdfruit_groenten\n",
      "   cat_Wijn_Stillewijnen_RAYON\n",
      "   rev_ticket\n",
      "   prod_ticket\n",
      "   SOW_colr\n",
      "\n",
      "LINEAR_NUMERIC (44):\n",
      "   masked_customer_id\n",
      "   jaar\n",
      "   cat_AP_STDR_PortoONLINE\n",
      "   cat_AP_STDR_WhiskyONLINE\n",
      "   cat_Babyluiers\n",
      "   cat_Ber_Ger_DVPortioneerbaar\n",
      "   cat_Ber_Ger_VersMaaltijdsalades\n",
      "   cat_Bier_Genietbieren\n",
      "   cat_Bloemen\n",
      "   cat_BroodKorthoudbaar\n",
      "   cat_ColruytMobile_Toestellen\n",
      "   cat_DeegDV\n",
      "   cat_EleKtroKeuken\n",
      "   cat_Houtpelletskolen_briketten\n",
      "   cat_Incontinentie_luiers\n",
      "   cat_KaasSeizoenskazen\n",
      "   cat_Kauwgum\n",
      "   cat_MelkKarnemelk\n",
      "   cat_Ontbijtgranen_Volwassenen\n",
      "   cat_ParfumerieEHBO\n",
      "   cat_Tapas\n",
      "   cat_Textiel_Bedlinnen\n",
      "   cat_Textiel_Herenondergoed\n",
      "   cat_Textiel_Pantys\n",
      "   cat_VNCBGBereidegerechten\n",
      "   cat_VNCBerBurgers\n",
      "   cat_VNCCharBHWildpasteien\n",
      "   cat_VNCFSalades\n",
      "   cat_VNCGevgeheel\n",
      "   cat_VNCKalfStoofvlees\n",
      "   cat_VNCLamSnedenkoteletsteak\n",
      "   cat_VNCRest\n",
      "   cat_VNCVarkenRest\n",
      "   cat_VNCWildSteak\n",
      "   cat_VerseKaasFruitkazen\n",
      "   cat_VisGerookt\n",
      "   cat_VisVerseSchelpdieren\n",
      "   cat_Zomerspeelgoed\n",
      "   cat_bbqfoodevent\n",
      "   cat_nfokay\n",
      "   total_discount\n",
      "   n_cogo\n",
      "   cogo_rev\n",
      "   price_sens_colr\n",
      "\n",
      "BINARY (0):\n",
      "\n",
      "CATEGORICAL (3):\n",
      "   Collishop_customer\n",
      "   HOUSEHOLDTYPOLOGY\n",
      "   SOW_type_colr\n",
      "\n",
      "Pipeline steps: ['preprocess', 'classifier']\n",
      "Some classifier param keys: ['classifier', 'classifier__C', 'classifier__class_weight', 'classifier__dual', 'classifier__fit_intercept', 'classifier__intercept_scaling', 'classifier__l1_ratio', 'classifier__max_iter', 'classifier__multi_class', 'classifier__n_jobs', 'classifier__penalty', 'classifier__random_state', 'classifier__solver', 'classifier__tol', 'classifier__verbose', 'classifier__warm_start']\n"
     ]
    }
   ],
   "source": [
    "gold_model, feature_groups = finalpipeline(X_train)\n",
    "\n",
    "# shows what feature is in which group\n",
    "for k, v in feature_groups.items():\n",
    "    print(f\"\\n{k.upper()} ({len(v)}):\")\n",
    "    for c in v:\n",
    "        print(\"  \", c)\n",
    "\n",
    "# Diagnostic: show pipeline steps and a few classifier parameter keys\n",
    "print('\\nPipeline steps:', list(gold_model.named_steps.keys()))\n",
    "print('Some classifier param keys:', [k for k in gold_model.get_params().keys() if k.startswith('classifier')][:30])\n",
    "\n",
    "# Hyperparameter grid (note: use the step name 'classifier' not 'model')\n",
    "# Use a list of dicts so we can avoid invalid solver/penalty combinations\n",
    "param_grid = [\n",
    "    {\n",
    "        'classifier__penalty': ['l2'],\n",
    "        'classifier__C': [0.01, 0.1, 1, 10],\n",
    "        'classifier__class_weight': [None, 'balanced'],\n",
    "        'classifier__solver': ['lbfgs', 'newton-cg']  # solvers compatible with l2\n",
    "    },\n",
    "    {\n",
    "        'classifier__penalty': ['l1'],\n",
    "        'classifier__C': [0.01, 0.1, 1, 10],\n",
    "        'classifier__class_weight': [None, 'balanced'],\n",
    "        'classifier__solver': ['saga']  # saga supports l1\n",
    "    }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "245fac24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 17\u001b[0m\n\u001b[0;32m      3\u001b[0m cv \u001b[38;5;241m=\u001b[39m StratifiedKFold(\n\u001b[0;32m      4\u001b[0m     n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m      5\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      6\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     10\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mgold_model,\n\u001b[0;32m     11\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     16\u001b[0m )\n\u001b[1;32m---> 17\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1363\u001b[0m     )\n\u001b[0;32m   1364\u001b[0m ):\n\u001b[1;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1046\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1047\u001b[0m     )\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1051\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:1605\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1603\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1604\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1605\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    993\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    994\u001b[0m         )\n\u001b[0;32m    995\u001b[0m     )\n\u001b[1;32m--> 997\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    999\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1000\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1001\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1017\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1018\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1019\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1020\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     73\u001b[0m warning_filters \u001b[38;5;241m=\u001b[39m warnings\u001b[38;5;241m.\u001b[39mfilters\n\u001b[0;32m     74\u001b[0m iterable_with_config_and_warning_filters \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     75\u001b[0m     (\n\u001b[0;32m     76\u001b[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     81\u001b[0m )\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py:1800\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n\u001b[0;32m   1790\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[0;32m   1791\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1795\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[0;32m   1796\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[0;32m   1797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1798\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n\u001b[0;32m   1799\u001b[0m     ):\n\u001b[1;32m-> 1800\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1801\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1803\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1804\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[0;32m   1805\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1811\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[0;32m   1812\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "\n",
    "cv = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=gold_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"f1\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8592da54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print best results AND all evaluation metrics, precision recall f1 false positives false engatives true pos true negatives\n",
    "print(\"Best CV F1 score:\", grid_search.best_score_)\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b892e513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27265b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6693bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a2ec01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328c7e47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
